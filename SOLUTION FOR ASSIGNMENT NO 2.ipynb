{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906b2d98",
   "metadata": {},
   "source": [
    "# Q-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af3a3a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\abhishek\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#install the selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca6cbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d75446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Abhishek\\Downloads\\chromedriver_win64.zip\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6350d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri.com on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e25c60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning designation and location  as required  in the question.\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7609e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "525e9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "628affe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the following details,making a list of indivisual\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "expirience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b3d1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data for the job title\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01e9f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data for the job location\n",
    "location_tags=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft fs12 lh16 locWdth']\")\n",
    "for j in location_tags[0:10]:\n",
    "    job_location.append(j.text)\n",
    "    job_location    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44bd2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping for the company name\n",
    "comapny_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for k in comapny_tags[0:10]:\n",
    "    company_name.append(k.text)\n",
    "    company_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb34a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the exprience required\n",
    "exp_tags=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft fs12 lh16 expwdth']\")\n",
    "for l in exp_tags[0:10]:\n",
    "    expirience_required.append(l.text)\n",
    "    expirience_required    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9773ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#finding the length of the above scrapping datas\n",
    "print(len(job_title),len(job_location),len(company_name),len(expirience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "954e2614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>company Name</th>\n",
       "      <th>Expirience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zen Data Shastra Llp</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru(Whitefield)</td>\n",
       "      <td>Zen Data Shastra Llp</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zscaler Softech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zscaler Softech</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zscaler Softech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zscaler Softech</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skillety</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Skillety</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Axtria</td>\n",
       "      <td>Noida, Pune, Gurgaon/Gurugram, Bangalore</td>\n",
       "      <td>Axtria</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jio</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jio</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Inspira Enterprise India</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Inspira Enterprise India</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dover</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Dover</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Job Title                                 Job Location  \\\n",
       "0      Zen Data Shastra Llp     Hybrid - Bangalore/Bengaluru(Whitefield)   \n",
       "1           Zscaler Softech                          Bangalore/Bengaluru   \n",
       "2           Zscaler Softech                          Bangalore/Bengaluru   \n",
       "3                  Skillety                          Bangalore/Bengaluru   \n",
       "4                    Axtria     Noida, Pune, Gurgaon/Gurugram, Bangalore   \n",
       "5                       Jio                          Bangalore/Bengaluru   \n",
       "6  Inspira Enterprise India                          Bangalore/Bengaluru   \n",
       "7               Wells Fargo  Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "8                     Dover                 Hybrid - Bangalore/Bengaluru   \n",
       "9             Shell Pvt Ltd                          Bangalore/Bengaluru   \n",
       "\n",
       "               company Name Expirience required  \n",
       "0      Zen Data Shastra Llp             2-6 Yrs  \n",
       "1           Zscaler Softech            5-10 Yrs  \n",
       "2           Zscaler Softech            5-10 Yrs  \n",
       "3                  Skillety             3-5 Yrs  \n",
       "4                    Axtria            7-12 Yrs  \n",
       "5                       Jio            8-10 Yrs  \n",
       "6  Inspira Enterprise India             3-4 Yrs  \n",
       "7               Wells Fargo            5-10 Yrs  \n",
       "8                     Dover             3-5 Yrs  \n",
       "9             Shell Pvt Ltd             2-5 Yrs  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the Dataframe \n",
    "df=pd.DataFrame({\"Job Title\":job_title,\"Job Location\":job_location,\"company Name\":company_name,\"Expirience required\":expirience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0844bc4",
   "metadata": {},
   "source": [
    "# End of Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc1845",
   "metadata": {},
   "source": [
    "# Q-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f94827",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Abhishek\\Downloads\\chromedriver_win64.zip\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6461fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri.com on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab86eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning designation and location  as required  in the question.\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a94278",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8a71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8265d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the following details,making a list of indivisual\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d9be6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birlasoft',\n",
       " 'Accenture',\n",
       " 'Optum',\n",
       " 'Optum',\n",
       " 'Optum',\n",
       " 'Mindtree',\n",
       " 'Baker Hughes',\n",
       " 'Walmart',\n",
       " 'Infosys',\n",
       " 'PPD']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the data for company name\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in title_tags[0:10]:\n",
    "    company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f78df68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hybrid - Noida, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hybrid - Noida, Kolkata, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the data for different locations\n",
    "location_tags=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft fs12 lh16 locWdth']\")\n",
    "for m in location_tags[0:10]:\n",
    "    job_location.append(m.text)\n",
    "job_location    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f43ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Analystics & Modeling Specialist',\n",
       " 'Senior Principal Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'DATA SCIENTIST III',\n",
       " 'Data Scientist',\n",
       " 'Opportunity For BioStatistician - II/Sr/Principal - Homebased/Blg/Mum/']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the job title\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for g in title_tags[0:10]:\n",
    "    job_title.append(g.text)\n",
    "job_title    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaf5e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#finding the length of the datas\n",
    "print(len(job_title),len(company_name),len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa1dda32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>location</th>\n",
       "      <th>company name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>Birlasoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...</td>\n",
       "      <td>Mindtree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DATA SCIENTIST III</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Opportunity For BioStatistician - II/Sr/Princi...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>PPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0                                     Data Scientist   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2                    Senior Principal Data Scientist   \n",
       "3                           Principal Data Scientist   \n",
       "4                              Senior Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7                                 DATA SCIENTIST III   \n",
       "8                                     Data Scientist   \n",
       "9  Opportunity For BioStatistician - II/Sr/Princi...   \n",
       "\n",
       "                                            location  company name  \n",
       "0  Hybrid - Noida, Hyderabad/Secunderabad, Pune, ...     Birlasoft  \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...     Accenture  \n",
       "2                                Bangalore/Bengaluru         Optum  \n",
       "3                                Bangalore/Bengaluru         Optum  \n",
       "4                                Bangalore/Bengaluru         Optum  \n",
       "5  Hybrid - Noida, Kolkata, Hyderabad/Secunderaba...      Mindtree  \n",
       "6                        Mumbai, Bangalore/Bengaluru  Baker Hughes  \n",
       "7                                Bangalore/Bengaluru       Walmart  \n",
       "8                                Bangalore/Bengaluru       Infosys  \n",
       "9  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...           PPD  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the dataframe \n",
    "df=pd.DataFrame({\"Job title\":job_title,'location':job_location,'company name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e40b3",
   "metadata": {},
   "source": [
    "# Q-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a2b91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8924fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce4da81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "search_field_designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")   #job  search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63d9c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d5cfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b534bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "#finding the delhi/ncr check box\n",
    "loc=driver.find_element(By.XPATH,\"//i[@class='fleft naukicon naukicon-checkbox']\")\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e1e300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "# finding the salary check box\n",
    "slry_box = driver.find_element(By.XPATH,\"//i[@class='fleft naukicon naukicon-checkbox']\")\n",
    "slry_box.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77eee6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1069bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f92e17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "#scraping the company_name \n",
    "companies=driver.find_elements(By.XPATH,\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e31b825c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior AR Caller</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Synergy Medsol</td>\n",
       "      <td>Gandhinagar, Ahmedabad(Anand Nagar +2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Purchase Engineer</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>(3 Reviews)</td>\n",
       "      <td>Ahmedabad(Hathijan +49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT Fresher</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Rameshwar Infra Creation Llp</td>\n",
       "      <td>Ahmedabad(Navrangpura)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Back Office Executive - Ahmedabad</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Softs Solution Service</td>\n",
       "      <td>Ahmedabad(Vijay Char Rasta)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Zealmax Innovations</td>\n",
       "      <td>Ahmedabad(Nehru Nagar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Social Media Executive (Female)</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>(13 Reviews)</td>\n",
       "      <td>Ahmedabad(Adinath Nagar +38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Qliksense Developer</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Zuru Tech India</td>\n",
       "      <td>Hybrid - Kolkata, Hyderabad/Secunderabad, Pune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wordpress Developer</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>(12 Reviews)</td>\n",
       "      <td>Ahmedabad(Sola)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HR Executive -Ahmedabad</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Boss Hydraulics</td>\n",
       "      <td>Ahmedabad(Navrangpura)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>(2 Reviews)</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_title experience_required  \\\n",
       "0                   Senior AR Caller             1-5 Yrs   \n",
       "1                  Purchase Engineer             3-7 Yrs   \n",
       "2                         IT Fresher             0-0 Yrs   \n",
       "3  Back Office Executive - Ahmedabad             0-1 Yrs   \n",
       "4                  Backend Developer             1-4 Yrs   \n",
       "5    Social Media Executive (Female)             1-3 Yrs   \n",
       "6                Qliksense Developer             3-5 Yrs   \n",
       "7                Wordpress Developer             3-7 Yrs   \n",
       "8            HR Executive -Ahmedabad             1-4 Yrs   \n",
       "9                     Java Developer             3-8 Yrs   \n",
       "\n",
       "                   company_name  \\\n",
       "0                Synergy Medsol   \n",
       "1                   (3 Reviews)   \n",
       "2  Rameshwar Infra Creation Llp   \n",
       "3        Softs Solution Service   \n",
       "4           Zealmax Innovations   \n",
       "5                  (13 Reviews)   \n",
       "6               Zuru Tech India   \n",
       "7                  (12 Reviews)   \n",
       "8               Boss Hydraulics   \n",
       "9                   (2 Reviews)   \n",
       "\n",
       "                                        job_location  \n",
       "0             Gandhinagar, Ahmedabad(Anand Nagar +2)  \n",
       "1                            Ahmedabad(Hathijan +49)  \n",
       "2                             Ahmedabad(Navrangpura)  \n",
       "3                        Ahmedabad(Vijay Char Rasta)  \n",
       "4                             Ahmedabad(Nehru Nagar)  \n",
       "5                       Ahmedabad(Adinath Nagar +38)  \n",
       "6  Hybrid - Kolkata, Hyderabad/Secunderabad, Pune...  \n",
       "7                                    Ahmedabad(Sola)  \n",
       "8                             Ahmedabad(Navrangpura)  \n",
       "9  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "            \n",
    "time.sleep(3)            \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4115b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "008ab336",
   "metadata": {},
   "source": [
    "# Q-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743d3cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC STAR</td>\n",
       "      <td>Riding Glasses, UV Protection Retro Square Sun...</td>\n",
       "      <td>₹393</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RESIST EYEWEAR</td>\n",
       "      <td>Polarized, Riding Glasses, UV Protection Wayfa...</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹129</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹129</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Fair-x</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹207</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,199</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                        Description  \\\n",
       "0           PC STAR  Riding Glasses, UV Protection Retro Square Sun...   \n",
       "1    RESIST EYEWEAR  Polarized, Riding Glasses, UV Protection Wayfa...   \n",
       "2        LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...   \n",
       "3         Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...   \n",
       "4        PHENOMENAL         UV Protection Retro Square Sunglasses (53)   \n",
       "..              ...                                                ...   \n",
       "115   VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "116          Fair-x              UV Protection Aviator Sunglasses (58)   \n",
       "117   VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "118            IDEE              UV Protection Aviator Sunglasses (58)   \n",
       "119       Elligator                UV Protection Round Sunglasses (53)   \n",
       "\n",
       "      Price     Discount  \n",
       "0      ₹393  No Discount  \n",
       "1    ₹1,399  No Discount  \n",
       "2      ₹129  No Discount  \n",
       "3      ₹149  No Discount  \n",
       "4      ₹129  No Discount  \n",
       "..      ...          ...  \n",
       "115    ₹949  No Discount  \n",
       "116    ₹207  No Discount  \n",
       "117    ₹949  No Discount  \n",
       "118  ₹1,199  No Discount  \n",
       "119    ₹199  No Discount  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it to search for sunglasses\n",
    "button=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements(By.CLASS_NAME,'_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "#scrapping all product Url\n",
    "product_url = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    url=driver.find_elements(By.XPATH,\"//a[@class='_2UzuFa']\")\n",
    "    for i in url:\n",
    "        product_url.append(i.get_attribute('href'))\n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))     #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "\n",
    "# scraping discount from each product url\n",
    "for product in product_url:\n",
    "    driver.get(product)\n",
    "    try:\n",
    "        disc=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[3]/div/div[3]/div[1]/div/div[3]/span\")# scraping the discount from the absolute xpath\n",
    "        discount.append(disc.text)\n",
    "    except NoSuchElementException:\n",
    "        discount.append(\"No Discount\")  \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand,\n",
    "                'Description':description,\n",
    "                'Price':price,\n",
    "                'Discount':discount})\n",
    "#printing dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0163f1",
   "metadata": {},
   "source": [
    "# Q-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29f0ce1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Simply Awesome\\n\\nI have upgraded from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Damn this phone is a blast . Upgraded from and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Worth the money’ starting first from its perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>Worst product delivered by Flipkart\\nAfter 10d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Flipkart honoured on time delivery, I have use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars           Short Review  \\\n",
       "0                5         Simply awesome   \n",
       "1                5       Perfect product!   \n",
       "2                5    Best in the market!   \n",
       "3                4        Value-for-money   \n",
       "4                5     Highly recommended   \n",
       "..             ...                    ...   \n",
       "95               5               Terrific   \n",
       "96               5    Best in the market!   \n",
       "97               5       Perfect product!   \n",
       "98               1      Absolute rubbish!   \n",
       "99               5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Simply Awesome\\n\\nI have upgraded from iPhone ...  \n",
       "96  Damn this phone is a blast . Upgraded from and...  \n",
       "97  Worth the money’ starting first from its perfo...  \n",
       "98  Worst product delivered by Flipkart\\nAfter 10d...  \n",
       "99  Flipkart honoured on time delivery, I have use...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages url\n",
    "url_1 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements(By.XPATH,\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "#Combining all the lists into a single dataframe\n",
    "df=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602486ec",
   "metadata": {},
   "source": [
    "# Q-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a92c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men  (Grey,...</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men  (Grey,...</td>\n",
       "      <td>₹295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Canvas Casual Partywear Outdoor Shoes For Boys...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mast &amp; Harbour</td>\n",
       "      <td>Sneakers For Men  (Grey)</td>\n",
       "      <td>₹824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cipramo Sports</td>\n",
       "      <td>Canvas Casual Sneakers For Walking,Running,Gym...</td>\n",
       "      <td>₹835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men  (Black...</td>\n",
       "      <td>₹891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men ...</td>\n",
       "      <td>₹474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price\n",
       "0         RapidBox                          Sneakers For Men  (White)  ₹599\n",
       "1           BRUTON  2 Combo Sneaker Shoes Sneakers For Men  (Grey,...  ₹599\n",
       "2           Shozie  2 Combo Sneaker Shoes Sneakers For Men  (Grey,...  ₹295\n",
       "3           Labbin  Modern Trendy Sneakers Shoes Sneakers For Men ...  ₹399\n",
       "4             aadi  Lightweight Pack Of 1 Trendy Sneakers Sneakers...  ₹359\n",
       "..             ...                                                ...   ...\n",
       "95          Labbin  Canvas Casual Partywear Outdoor Shoes For Boys...  ₹399\n",
       "96  Mast & Harbour                           Sneakers For Men  (Grey)  ₹824\n",
       "97  Cipramo Sports  Canvas Casual Sneakers For Walking,Running,Gym...  ₹835\n",
       "98        Roadster  2 Combo Sneaker Shoes Sneakers For Men  (Black...  ₹891\n",
       "99        Red Rose  Modern Trendy Sneakers Shoes Sneakers For Men ...  ₹474\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#close log_in window\n",
    "log_in_pop_up = driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it to search for sneakers\n",
    "button=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements(By.CLASS_NAME,'_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        \n",
    "        \n",
    "time.sleep(2)        \n",
    "# Since in some records not getting description so try from inside of urls\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):#for loop for scrapping 4 page\n",
    "    \n",
    "    product_url = driver.find_elements(By.XPATH,\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "time.sleep(2)        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements(By.XPATH,'//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "time.sleep(2)        \n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100]})\n",
    "#printing dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40320c",
   "metadata": {},
   "source": [
    "# Q-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91057fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...</td>\n",
       "      <td>99,990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGB Octev GA-9009 15.6\"Laptop (Intel Core i7-1...</td>\n",
       "      <td>75,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>81,990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>82,150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>82,990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>94,630</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td>1,49,900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>88,141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td>91,490</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...</td>\n",
       "      <td>1,04,990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     Price  Ratings\n",
       "0  Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...    99,990      NaN\n",
       "1  AGB Octev GA-9009 15.6\"Laptop (Intel Core i7-1...    75,000      NaN\n",
       "2  HP Victus Gaming Latest 12th Gen Intel Core i7...    81,990      NaN\n",
       "3  HP Pavilion x360 11th Gen Intel Core i7 14 inc...    82,150      NaN\n",
       "4  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...    82,990      NaN\n",
       "5  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    94,630      NaN\n",
       "6  ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...  1,49,900      NaN\n",
       "7  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...    88,141      NaN\n",
       "8  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....    91,490      NaN\n",
       "9  Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...  1,04,990      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar = driver.find_element(By.ID,\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element(By.XPATH,'//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)\n",
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements(By.XPATH,\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles\n",
    "titles=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price\n",
    "prices=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#locating Ratings\n",
    "urls=driver.find_elements(By.XPATH,\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception                                                    #click the rating link found\n",
    "        rating=driver.find_element(By.XPATH,\"//span[@class='a-size-base a-nowrap']//span\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there\n",
    "        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame(index = list(range(0,10)))\n",
    "df[\"title\"]=pd.Series(Title)\n",
    "df[\"Price\"]=pd.Series(price)\n",
    "df[\"Ratings\"]=pd.Series(Ratings)\n",
    "#printing dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922e0da",
   "metadata": {},
   "source": [
    "# Q-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "524195bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"http://www.azquotes.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "Quotes=[]\n",
    "Author=[]\n",
    "Type_of_quote=[]\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd15ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec8ba1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data for the top quotes\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end)[:1000]:\n",
    "    quotes=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "    for i in quotes:\n",
    "        Quotes.append(i.text) \n",
    "    next_button=driver.find_elements(By.XPATH,\"//li[@class='next']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8279eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#scrapping the data for the type of the quotes\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end)[:1000]:\n",
    "    types_of_quotes=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "    for l in types_of_quotes:\n",
    "        Type_of_quote.append(l.text)\n",
    "    next_button=driver.find_elements(By.XPATH,\"//li[@class='next']\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3eac860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#scrapping the data for the author\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end)[:1000]:\n",
    "    author=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "    for j in author:\n",
    "        Author.append(j.text)\n",
    "    next_button=driver.find_elements(By.XPATH,\"//li[@class='next']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "519a4ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "#finding the length of the data\n",
    "print(len(Quotes),len(Author),len(Type_of_quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9d8ffd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Type_of_quote</th>\n",
       "      <th>Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Author                             Type_of_quote  \\\n",
       "0          Michael Porter  Essence, Deep Thought, Transcendentalism   \n",
       "1              Golda Meir                 Inspiration, Past, Trying   \n",
       "2      Theodore Roosevelt                       Country, Peace, War   \n",
       "3          Nelson Mandela        Inspirational, Motivational, Death   \n",
       "4            Erma Bombeck              4th Of July, Food, Patriotic   \n",
       "..                    ...                                       ...   \n",
       "995    Hunter S. Thompson                    Music, Sports, Hunting   \n",
       "996       Corrie Ten Boom             Trust, Encouraging, Uplifting   \n",
       "997            Dalai Lama              Inspirational, Funny, Change   \n",
       "998         Mother Teresa                      Success, God, Mother   \n",
       "999  Norman Vincent Peale       Inspirational, Motivational, Change   \n",
       "\n",
       "                                                Quotes  \n",
       "0    The essence of strategy is choosing what not t...  \n",
       "1    One cannot and must not try to erase the past ...  \n",
       "2    Patriotism means to stand by the country. It d...  \n",
       "3    Death is something inevitable. When a man has ...  \n",
       "4    You have to love a nation that celebrates its ...  \n",
       "..                                                 ...  \n",
       "995     When the going gets weird, the weird turn pro.  \n",
       "996  When a train goes through a tunnel and it gets...  \n",
       "997  If you think you are too small to make a diffe...  \n",
       "998  God doesn't require us to succeed, he only req...  \n",
       "999    Change your thoughts and you change your world.  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the dataframe\n",
    "df=pd.DataFrame(index=list(range(0,1000)))\n",
    "df[\"Author\"]=pd.Series(Author)\n",
    "df[\"Type_of_quote\"]=pd.Series(Type_of_quote)\n",
    "df[\"Quotes\"]=pd.Series(Quotes)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb949d07",
   "metadata": {},
   "source": [
    "# Q-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b6f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"http://www.jagranjosh.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8ae67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click for the GK option\n",
    "GK=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "GK.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9afbf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the prime minister list and click the button\n",
    "Prime_minister=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "Prime_minister.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e55e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jawahar Lal Nehru']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the Name of all respected Prime minister\n",
    "Name=[]\n",
    "name=driver.find_elements(By.XPATH,\"//*[@id='itemdiv']/div[4]/span/div[2]/table/tbody/tr[2]/td[2]/p/strong\")\n",
    "for i in name[:50]:\n",
    "    Name.append(i.text)\n",
    "Name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341a97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15b124cc",
   "metadata": {},
   "source": [
    "# Q-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6b301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.motor1.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2629707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_bar=driver.find_element(By.XPATH,\"//li[@class='grand left top mobile dropdown']\")\n",
    "Feature_bar.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5feb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_car=driver.find_element(By.XPATH,\"/html/body/div[3]/div[7]/div/div[1]/div[1]/div[2]/div/div[1]/h3/a\")\n",
    "expensive_car.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30383ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drako GTE',\n",
       " 'De Tomaso P72',\n",
       " 'Ferrari LaFerrari',\n",
       " 'Pagani Huayra',\n",
       " 'McLaren Elva',\n",
       " 'Czinger 21C',\n",
       " 'Ferrari Monza',\n",
       " 'Gordon Murray T.33',\n",
       " 'Koenigsegg Gemera',\n",
       " 'Zenvo TSR-S',\n",
       " 'Hennessey Venom F5',\n",
       " 'Bentley Bacalar',\n",
       " 'Hispano Suiza Carmen Boulogne',\n",
       " 'Bentley Mulliner Batur',\n",
       " 'Deus Vayanne',\n",
       " 'SSC Tuatara',\n",
       " 'Lotus Evija',\n",
       " 'Aston Martin Vulcan',\n",
       " 'Delage D12',\n",
       " 'McLaren Speedtail',\n",
       " 'Rimac Nevera',\n",
       " 'Pagani Utopia',\n",
       " 'Pininfarina Battista',\n",
       " 'Ferrari FXX K Evo',\n",
       " 'Gordon Murray T.50',\n",
       " 'Lamborghini Countach',\n",
       " 'Mercedes-AMG Project One',\n",
       " 'Aston Martin Victor',\n",
       " 'Hennessey Venom F5 Roadster',\n",
       " 'Koenigsegg Jesko',\n",
       " 'Aston Martin Valkyrie',\n",
       " 'W Motors Lykan Hypersport',\n",
       " 'McLaren Solus',\n",
       " 'Pagani Huayra Roadster BC',\n",
       " 'Bugatti Chiron Pur Sport',\n",
       " 'Lamborghini Sian',\n",
       " 'Koenigsegg CC850',\n",
       " 'Bugatti Chiron Super Sport 300+',\n",
       " 'Lamborghini Veneno',\n",
       " 'Bugatti Bolide',\n",
       " 'Bugatti Mistral',\n",
       " 'Pagani Huayra Imola',\n",
       " 'Bugatti Divo',\n",
       " 'SP Automotive Chaos',\n",
       " 'Pagani Codalunga',\n",
       " 'Mercedes-Maybach Exelero',\n",
       " 'Bugatti Centodieci',\n",
       " 'Rolls-Royce Sweptail',\n",
       " 'Bugatti La Voiture Noire',\n",
       " 'Rolls-Royce Boat Tail*']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_name=[]\n",
    "page=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in page[:50]:\n",
    "    car_name.append(i.text)\n",
    "car_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80fed084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Price: $1.7 Million']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping the price data\n",
    "price=[]\n",
    "page=driver.find_elements(By.XPATH,\"//*[@id='article_box']/div[1]/div[2]/div[1]/p[22]/strong\")\n",
    "for j in page[:50]:\n",
    "    price.append(j.text)\n",
    "price    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae412fe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: Unable to locate an element with the xpath expression //[@id='article_box']/div[1]/div[2]/div[1]/p[5] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//[@id='article_box']/div[1]/div[2]/div[1]/p[5]' is not a valid XPath expression.\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0097F243]\n\t(No symbol) [0x00907FD1]\n\t(No symbol) [0x007FD04D]\n\t(No symbol) [0x007FFD34]\n\t(No symbol) [0x007FFBE5]\n\t(No symbol) [0x007FFE80]\n\t(No symbol) [0x0082BD55]\n\t(No symbol) [0x0082C22B]\n\t(No symbol) [0x0085E64C]\n\t(No symbol) [0x008485D4]\n\t(No symbol) [0x0085C9EB]\n\t(No symbol) [0x00848386]\n\t(No symbol) [0x0082163C]\n\t(No symbol) [0x0082269D]\n\tGetHandleVerifier [0x00C19A22+2655074]\n\tGetHandleVerifier [0x00C0CA24+2601828]\n\tGetHandleVerifier [0x00A28C0A+619850]\n\tGetHandleVerifier [0x00A27830+614768]\n\t(No symbol) [0x009105FC]\n\t(No symbol) [0x00915968]\n\t(No symbol) [0x00915A55]\n\t(No symbol) [0x0092051B]\n\tBaseThreadInitThunk [0x75FE6939+25]\n\tRtlGetFullPathName_UEx [0x77CD8FD2+1218]\n\tRtlGetFullPathName_UEx [0x77CD8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#scrapping the discription for the page\u001b[39;00m\n\u001b[0;32m      2\u001b[0m disc\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 3\u001b[0m page\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//[@id=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle_box\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]/div[1]/div[2]/div[1]/p[5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m page:\n\u001b[0;32m      5\u001b[0m     disc\u001b[38;5;241m.\u001b[39mappend(k\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:892\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    888\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidSelectorException\u001b[0m: Message: invalid selector: Unable to locate an element with the xpath expression //[@id='article_box']/div[1]/div[2]/div[1]/p[5] because of the following error:\nSyntaxError: Failed to execute 'evaluate' on 'Document': The string '//[@id='article_box']/div[1]/div[2]/div[1]/p[5]' is not a valid XPath expression.\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0097F243]\n\t(No symbol) [0x00907FD1]\n\t(No symbol) [0x007FD04D]\n\t(No symbol) [0x007FFD34]\n\t(No symbol) [0x007FFBE5]\n\t(No symbol) [0x007FFE80]\n\t(No symbol) [0x0082BD55]\n\t(No symbol) [0x0082C22B]\n\t(No symbol) [0x0085E64C]\n\t(No symbol) [0x008485D4]\n\t(No symbol) [0x0085C9EB]\n\t(No symbol) [0x00848386]\n\t(No symbol) [0x0082163C]\n\t(No symbol) [0x0082269D]\n\tGetHandleVerifier [0x00C19A22+2655074]\n\tGetHandleVerifier [0x00C0CA24+2601828]\n\tGetHandleVerifier [0x00A28C0A+619850]\n\tGetHandleVerifier [0x00A27830+614768]\n\t(No symbol) [0x009105FC]\n\t(No symbol) [0x00915968]\n\t(No symbol) [0x00915A55]\n\t(No symbol) [0x0092051B]\n\tBaseThreadInitThunk [0x75FE6939+25]\n\tRtlGetFullPathName_UEx [0x77CD8FD2+1218]\n\tRtlGetFullPathName_UEx [0x77CD8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "#scrapping the discription for the page\n",
    "disc=[]\n",
    "page=driver.find_elements(By.XPATH,\"//[@id='article_box']/div[1]/div[2]/div[1]/p[5]\")\n",
    "for k in page:\n",
    "    disc.append(k.text)\n",
    "disc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10978267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the Dataframe\n",
    "df=pd.DataFrame({\"Car Name\":car_name,\"Price\":price,\"Discription\":disc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef481ec4",
   "metadata": {},
   "source": [
    "# TOTAL SOLVED QUESTIONS=8\n",
    "HAVING PROBLEM=2 QUESTIONS(Q-9,Q-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661ce78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c8401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348f910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ec139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
